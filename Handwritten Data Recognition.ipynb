{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "de0a5276",
   "metadata": {},
   "source": [
    "# Handwritten Data Recognition "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d30bc13f",
   "metadata": {},
   "source": [
    "#### This script is a small demo demonstrating how CNN can be used for processing Handwritten Text in images. The script will demonstrate how to extract the text of an image with handwritten text by me. Unfortunately due to time constraints it will only be able to print the text of one image to the console. Of course the image can be changed and the application can be tested with another one. The script is split into 5 different sections as follows:\n",
    "    1. Preparation of the train/test datasets and images - where the Handwritten A-Z CSV Dataset will be transformed to images and the images of the letters will be split to train and test datasets.\n",
    "    2. Definition of the CNN model.\n",
    "    3. Training of the model - where the model will be trained using the train and test letters. Since it could take a lot of time (~3hours), there is an option to load and use an already trained model. \n",
    "    4. Preparation of the handwritten image - this includes transformations and processes such as tresholding the image, line detections and segmentations of the different characters. So that the whole string can be split up to different characters.\n",
    "    5. The output - through the use of the model, the different characters will be recognized and the whole sentence of the image will be printed to the console."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ccca5be",
   "metadata": {},
   "source": [
    "#### Installations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5982fd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For output cleaning\n",
    "from IPython.display import clear_output\n",
    "\n",
    "# Remove the comments in order to perform the necessary installations!\n",
    "\n",
    "#!pip install pandas\n",
    "#!pip install ipynb\n",
    "#!pip install numpy\n",
    "#!pip install torch\n",
    "#!pip install pillow\n",
    "#!pip install matplotlib\n",
    "#!pip install torchvision\n",
    "#!pip install opencv-python\n",
    "\n",
    "# Clear the output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "053ba381",
   "metadata": {},
   "source": [
    "#### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef7d4607",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'clear_output' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25820/2627680025.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     22\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;31m# Clear the output\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m \u001b[0mclear_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'clear_output' is not defined"
     ]
    }
   ],
   "source": [
    "# Import the necessary libraries.\n",
    "\n",
    "import cv2\n",
    "import csv\n",
    "import torch\n",
    "import ipynb\n",
    "import string\n",
    "import numpy as np\n",
    "import os, os.path\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from torch import nn, optim\n",
    "import matplotlib.pyplot as plt\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "# Import the needed functions from functions.ipynb.\n",
    "from ipynb.fs.full.functions import ref_arr, w_letter, l_end_arr, ref_end_word, l_arr, segmentation\n",
    "\n",
    "# Adjustments to matplot.\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "# Clear the output\n",
    "clear_output()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac25840a",
   "metadata": {},
   "source": [
    "### 1. Preparation of the train/test datasets and images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0896c980",
   "metadata": {},
   "source": [
    "#### A_Z-Handwritten Dataset will be transformed from CSV  to images.\n",
    "The dataset will be transformed from csv to images\n",
    "and they will be saved to the train/test folders.\n",
    "NOTE - This process takes a bit of time, therefore the already transformed images will be added. Meaning that the following code can be skipped. Otherwise the images from each folder must be deleted and the code must be run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2457c777",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26024/791478322.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     30\u001b[0m         \u001b[1;31m# Increment counter and save the image to the correct directory.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     31\u001b[0m         \u001b[0mnum\u001b[0m\u001b[1;33m+=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 32\u001b[1;33m         \u001b[0mimg\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mc:\\users\\valeri\\appdata\\local\\programs\\python\\python38\\lib\\site-packages\\PIL\\Image.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, fp, format, **params)\u001b[0m\n\u001b[0;32m   2207\u001b[0m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"r+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2208\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2209\u001b[1;33m                 \u001b[0mfp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbuiltins\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"w+b\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2210\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2211\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Path to csv dataset (change to your location).\n",
    "csvpath = 'D:\\A_Z-Handwritten-Data.csv'\n",
    "\n",
    "# Open the csv file.\n",
    "with open(csvpath, newline='') as file:\n",
    "    # Init variables.\n",
    "    num = 0\n",
    "    prev_digit =  None\n",
    "    letters_list = list(string.ascii_uppercase)\n",
    "    data = csv.reader(file, delimiter=',', quotechar='|')\n",
    "    \n",
    "    # Loop through each row.\n",
    "    for r in data:\n",
    "        # Get and remove the first digit, then make the row an array, then an image.\n",
    "        digit = r.pop(0)\n",
    "        img_arr = (np.asarray(r)).reshape(28, 28)\n",
    "        img = Image.fromarray(img_arr.astype('uint8'))\n",
    "        \n",
    "        # Check if a new letter has started to be processed, if so reset the counter.\n",
    "        if str(letters_list[(int)(digit)]) != prev_digit:\n",
    "            prev_digit = str(letters_list[(int)(digit)])\n",
    "            num = 0\n",
    "        \n",
    "        # Randomly split the images to the training and test folders.\n",
    "        if np.random.randint(6) != 0:\n",
    "          path = 'D:/Letters/train/{0}/{1}_{2}.png'.format(prev_digit, str(prev_digit), str(num))\n",
    "        else :\n",
    "          path = 'D:/Letters/test/{0}/{1}_{2}.png'.format(prev_digit, str(prev_digit), str(num))\n",
    "        \n",
    "        # Increment counter and save the image to the correct directory. \n",
    "        num+=1\n",
    "        img.save(path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71defb94",
   "metadata": {},
   "source": [
    "#### Necessary transformations will be applied to the letter images through torch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6b9c3caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a transform which will be applied to all images.\n",
    "transform = transforms.Compose([\n",
    "    # Crop images at center.\n",
    "    transforms.CenterCrop(21),\n",
    "    # Resize images to 28px.\n",
    "    transforms.Resize(28), \n",
    "    # Convert image to floattensor shape.\n",
    "    transforms.ToTensor(),\n",
    "    # Normalize with mean and standard deviation.\n",
    "    transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "# Apply transforms to both training and test images.\n",
    "train = datasets.ImageFolder('D:/Letters/train', transform=transform)\n",
    "test = datasets.ImageFolder('D:/Letters/test', transform=transform)\n",
    "\n",
    "# Init data loaders.\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=32, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test, batch_size=32, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32bcd5fd",
   "metadata": {},
   "source": [
    "### 2. Defining a Convolutional Neural Network Model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f42fe52a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining the CNN model.\n",
    "class Model(nn.Module):\n",
    "  def __init__(self):\n",
    "    super().__init__()\n",
    "    self.layer1 = nn.Linear(2352,784)\n",
    "    self.layer2 = nn.Linear(784,256)\n",
    "    self.layer3 = nn.Linear(256,256)\n",
    "    self.layer4 = nn.Linear(256,128)\n",
    "    self.layer5 = nn.Linear(128,64)\n",
    "    self.layer6 = nn.Linear(64,26)\n",
    "    self.relu = nn.ReLU()\n",
    "    self.ls = nn.LogSoftmax( dim=1)\n",
    "  def forward(self, img):\n",
    "        flattened = img.view(img.shape[0], -1) \n",
    "        activation1 = self.relu(self.layer1(flattened))\n",
    "        activation2 = self.relu(self.layer2(activation1))\n",
    "        activation3 = self.relu(self.layer3(activation2))\n",
    "        activation4 = self.relu(self.layer4(activation3))\n",
    "        activation5 = self.relu(self.layer5(activation4))\n",
    "        output = self.ls(self.layer6(activation5))\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6431d50f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign the classifier.\n",
    "model = Model()\n",
    "# Using the negative log likelihood loss. \n",
    "criterion = nn.NLLLoss()\n",
    "# Define stochastic gradient descen with learning rate and parameters. \n",
    "optimizer = optim.SGD(model.parameters(), lr = 0.005)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b7ee3f7",
   "metadata": {},
   "source": [
    "### 3. Training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77193e5b",
   "metadata": {},
   "source": [
    "NOTE - This process could take around 3 hours due to the large amount of images. For example, 17:15 started, 19:06 first epoch completed, 19:30 second epoch completed, 20:02 third epoch completed.\n",
    "NOTE-2 - This process may be skipped and you can load the already created, trained model \"my_model.pth\" to save time. The code for loading the model is bellow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4aad4940",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n"
     ]
    }
   ],
   "source": [
    "# Loop three times over the dataset for better accuracy. \n",
    "for epoch in range(3):\n",
    "    running_loss = 0\n",
    "    for img, lbl in train_loader:\n",
    "        # Make parameter gradients zero. \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(img)\n",
    "        loss = criterion(outputs, lbl)\n",
    "        # Computer gradient of loss. \n",
    "        loss.backward()\n",
    "        # Iter over all param (tensors) and update their values.\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    #print(epoch) for checking progress"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b14c6b8f",
   "metadata": {},
   "source": [
    "#### Load the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "97833b9c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the model.\n",
    "model = Model()\n",
    "model.load_state_dict(torch.load(\"./my_model.pth\"))  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbeea3f",
   "metadata": {},
   "source": [
    "### 4. Preparation of the images."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9efbf9c8",
   "metadata": {},
   "source": [
    "#### Images Thresholding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "0e0e4434",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read image, make a copy and get width/height.\n",
    "image = cv2.imread('D:/test-img.jpg', 1)\n",
    "image_copy = image.copy()\n",
    "height = image.shape[0]\n",
    "width = image.shape[1]\n",
    "\n",
    "# Resize image.\n",
    "rsz = int(1320 * height / width)\n",
    "image = cv2.resize(image_copy, dsize =(1320, rsz), interpolation = cv2.INTER_AREA)\n",
    "\n",
    "# Reasigning width and height.\n",
    "height = image.shape[0]\n",
    "width = image.shape[1]\n",
    "\n",
    "# Make image gray.\n",
    "image_grey = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Apply adaptive threshold and make 2 copies.\n",
    "image_thr = cv2.adaptiveThreshold(image_grey, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY_INV, 21, 20)\n",
    "image_cp1 = image_thr.copy()\n",
    "image_cp2 = image_thr.copy()\n",
    "\n",
    "# Get the kernel as morph shape.\n",
    "k = cv2.getStructuringElement(cv2.MORPH_ELLIPSE,(3,3))\n",
    "k1 = np.array([[1,0,1],[0,1,0],[1,0,1]], dtype = np.uint8)\n",
    "\n",
    "# Remove noise from the image.\n",
    "final = cv2.morphologyEx(image_thr, cv2.MORPH_CLOSE, k)\n",
    "final_copy = final.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0570fb",
   "metadata": {},
   "source": [
    "#### Line Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e203da6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_count = np.zeros(shape= (height))\n",
    "for h in range(height):\n",
    "    for w in range(width):\n",
    "        if image_thr[h][w] == 255 :\n",
    "            x_count[h] += 1\n",
    "\n",
    "\n",
    "# Call line array function to get the higher and lower lines.\n",
    "higher, lower = l_arr(x_count)\n",
    "\n",
    "# Call the refine array function to refine the higher and lower lines.\n",
    "lines_higher, lines_lower = ref_arr(higher, lower)\n",
    "\n",
    "len_lhigher = len(lines_higher)\n",
    "len_llower = len(lines_lower)\n",
    "all_lines = []\n",
    "\n",
    "# Fill all lines array.\n",
    "if len_lhigher == len_llower:\n",
    "    for i in lines_higher:\n",
    "        final[i][:] = 255\n",
    "    for i in lines_lower:\n",
    "        final[i][:] = 255\n",
    "    for i in range(len_lhigher):\n",
    "        all_lines.append((lines_higher[i], lines_lower[i]))\n",
    "else:\n",
    "    print(\"Error! Try with another image!\")\n",
    "    \n",
    "all_lines = np.array(all_lines)\n",
    "lines_num = len(all_lines)\n",
    "lines_image = []\n",
    "\n",
    "# Set the image lines.\n",
    "for i in range(lines_num):\n",
    "    lines_image.append(image_cp2[all_lines[i][0]:all_lines[i][1], :])\n",
    "    \n",
    "# Letter width detection.\n",
    "cont, hier = cv2.findContours(final_copy,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "final_copy = np.zeros((final.shape[0], final.shape[1],3), dtype = np.uint8)\n",
    "\n",
    "# Draw the contours.\n",
    "cv2.drawContours(image, cont, -1, (0,255,0), 1)\n",
    "\n",
    "# Set mean width of each letter.\n",
    "mean_w = w_letter(cont)\n",
    "\n",
    "# Function to detect new lines.\n",
    "def nl_detect(all_lines, index, image_thr, mean_w):\n",
    "    # Arr of zeros.\n",
    "    count = np.zeros(shape = width)\n",
    "    for i in range(width):\n",
    "        for j in range(all_lines[index][0],all_lines[index][1]):\n",
    "            if image_thr[j][i] == 255:\n",
    "                # Increment.\n",
    "                count[i] = count[i] + 1\n",
    "    # Call function to get array of end lines.\n",
    "    endlines = l_end_arr(count, int(mean_w))\n",
    "    # Call function to refine the end lines. \n",
    "    end_lines = ref_end_word(endlines)\n",
    "    for i in end_lines:\n",
    "        final[all_lines[index][0]:all_lines[index][1], i] = 255\n",
    "    return end_lines\n",
    "\n",
    "lines_new = []\n",
    "r1 = len(lines_image)\n",
    "\n",
    "# Detect the new lines.\n",
    "for i in range(r1):\n",
    "    lines_new.append(nl_detect(all_lines, i, image_thr, mean_w))\n",
    "\n",
    "# Get the number of new lines.\n",
    "r2 = len(lines_new)\n",
    "\n",
    "for i in range(r2):\n",
    "    lines_new[i].append(width)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85558ed1",
   "metadata": {},
   "source": [
    "####  Segmentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "0f250473",
   "metadata": {},
   "outputs": [],
   "source": [
    "range1 = len(all_lines)\n",
    "\n",
    "# Call the segmentation for each line of the image. \n",
    "for i in range(range1):\n",
    "    segmentation(lines_image, lines_new, i)\n",
    "    \n",
    "# Segmentation of chars.\n",
    "char_image = image_cp1.copy()\n",
    "\n",
    "# Find the contours.\n",
    "cont, hier = cv2.findContours(char_image,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_SIMPLE)\n",
    "for c in cont:\n",
    "    if cv2.contourArea(c) >= 21:\n",
    "        x, y, width, height = cv2.boundingRect(c)\n",
    "        cv2.rectangle(image,(x, y),(x + width, y + height),(0, 255, 0), 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acb69cfb",
   "metadata": {},
   "source": [
    "#### Get files and paths of the segmented image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f72de639",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get file names in the folder and their number.\n",
    "path, dirs, files = next(os.walk(\"D:/segmented_img/img1\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c74d4e52",
   "metadata": {},
   "source": [
    "### 5. Printing the handwritten sentence  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2c735d2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HEY PIDAJ \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create transform with normalization.\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "  transforms.Normalize((0.5,0.5,0.5), (0.5,0.5,0.5))\n",
    "])\n",
    "\n",
    "data = datasets.ImageFolder('D:/segmented_img/', transform=transform)\n",
    "# Create loader with length of character files. \n",
    "l = torch.utils.data.DataLoader(data, batch_size=len(files))\n",
    "images, lbls = next(iter(l))\n",
    "img = images[2].view(1, 2352)\n",
    "\n",
    "# Init variables.\n",
    "sentence = ''\n",
    "c = 1\n",
    "word_num = []\n",
    "line_num =[]\n",
    "\n",
    "# Add the indexex of lines and words.\n",
    "for f in files:\n",
    "  word_num.append(f[2])\n",
    "  line_num.append(f[0])\n",
    "\n",
    "# Add -2 to check for end of word/line.\n",
    "word_num.append(-2)\n",
    "line_num.append(-2)\n",
    "\n",
    "# Loop through all images.\n",
    "for i in images:\n",
    "  img = i.view(1, 2352)\n",
    "  # Model outputs log probabilities.\n",
    "  with torch.no_grad():\n",
    "      out = model(img)\n",
    "  ps = torch.exp(out)\n",
    "  amax = ps.argmax(1)\n",
    "  # Combine the new letter to the sentence. \n",
    "  sentence = sentence + str(chr(amax.item()+65))\n",
    "  # Add space if needed.\n",
    "  if word_num[c] != word_num[c-1]:\n",
    "    sentence = sentence + \" \"\n",
    "  # Add new line if needed.\n",
    "  if line_num[c] != line_num[c-1]:\n",
    "    sentece = sentence + \"\\n\"\n",
    "  # Increment counter.\n",
    "  c = c + 1\n",
    "\n",
    "# Print the handwritten sentence. \n",
    "print(sentece)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5590b9e",
   "metadata": {},
   "source": [
    "#### Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "09dec8c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model.\n",
    "torch.save(model.state_dict(), 'new_model.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
